{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7fR7dgQotGl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import json\n",
        "\n",
        "def load_jsonl(path):\n",
        "    ds = tf.data.TextLineDataset(path)\n",
        "\n",
        "    def parse_line(line):\n",
        "        obj = tf.py_function(lambda s: json.loads(s.numpy()), [line], Tout=tf.string)\n",
        "        return obj\n",
        "\n",
        "    return ds.map(parse_line)\n",
        "dataset = load_jsonl(\"mixed_dataset.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9Gv_iikqbhy",
        "outputId": "6ebc6a10-4dda-4bc8-a258-0530d7a7fcda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizer trained: tinyllm.model, tinyllm.vocab\n"
          ]
        }
      ],
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "spm.SentencePieceTrainer.Train(\n",
        "    input='mixed_dataset.jsonl',\n",
        "    model_prefix='tinyllm',\n",
        "    vocab_size=16000,\n",
        "    character_coverage=1.0,\n",
        "    model_type='bpe',\n",
        "    pad_id=0,\n",
        "    unk_id=1,\n",
        "    bos_id=2,\n",
        "    eos_id=3,\n",
        "    user_defined_symbols=[\"<user>\", \"<assistant>\"]\n",
        ")\n",
        "\n",
        "print(\"Tokenizer trained: tinyllm.model, tinyllm.vocab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLjNC-e2qc9T"
      },
      "outputs": [],
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(\"tinyllm.model\")\n",
        "\n",
        "MAX_LEN = 256\n",
        "PAD_ID = 0 if sp.pad_id() < 0 else sp.pad_id()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGe9ul_xqesr"
      },
      "outputs": [],
      "source": [
        "def encode_example(text):\n",
        "    ids = sp.encode(text, out_type=int)\n",
        "\n",
        "    if len(ids) > MAX_LEN:\n",
        "        ids = ids[:MAX_LEN]\n",
        "\n",
        "    x = ids[:-1]\n",
        "    y = ids[1:]\n",
        "\n",
        "    # pad\n",
        "    x = x + [PAD_ID] * (MAX_LEN - len(x))\n",
        "    y = y + [PAD_ID] * (MAX_LEN - len(y))\n",
        "\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3R-8KVOqf7B"
      },
      "outputs": [],
      "source": [
        "def tf_load_dataset(path, batch_size=8):\n",
        "    ds = tf.data.TextLineDataset(path)\n",
        "\n",
        "    def parse_json(line):\n",
        "        obj = json.loads(line.numpy().decode(\"utf-8\"))\n",
        "        return obj[\"text\"]\n",
        "\n",
        "    def tf_parse_json(line):\n",
        "        text = tf.py_function(parse_json, [line], Tout=tf.string)\n",
        "        text.set_shape([])  # VERY IMPORTANT\n",
        "        return text\n",
        "\n",
        "    def tf_encode(text):\n",
        "        x, y = tf.py_function(\n",
        "            lambda t: encode_example(t.numpy().decode(\"utf-8\")),\n",
        "            [text],\n",
        "            [tf.int32, tf.int32]\n",
        "        )\n",
        "        # Set shapes MANUALLY (the fix for your error)\n",
        "        x.set_shape([MAX_LEN])\n",
        "        y.set_shape([MAX_LEN])\n",
        "        return x, y\n",
        "\n",
        "    ds = ds.map(tf_parse_json, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.map(tf_encode, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.shuffle(20000)\n",
        "    ds = ds.batch(batch_size, drop_remainder=True)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPSbM0HvqiZt"
      },
      "outputs": [],
      "source": [
        "train_ds = tf_load_dataset(\"mixed_dataset.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k36ZCZVTqkTD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class DecoderBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, d_ff):\n",
        "        super().__init__()\n",
        "        self.att = tf.keras.layers.MultiHeadAttention(\n",
        "          num_heads=num_heads,\n",
        "          key_dim=d_model // num_heads\n",
        "        )\n",
        "\n",
        "        self.ln1 = tf.keras.layers.LayerNormalization()\n",
        "        self.ff = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(d_ff, activation=\"gelu\"),\n",
        "            tf.keras.layers.Dense(d_model)\n",
        "        ])\n",
        "        self.ln2 = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "    def call(self, x, causal_mask):\n",
        "        #attn = self.att(x, x, attention_mask=causal_mask[:, :, :tf.shape(x)[1], :tf.shape(x)[1]])\n",
        "        attn = self.att(x, x, attention_mask=causal_mask)\n",
        "        x = self.ln1(x + attn)\n",
        "        ff_out = self.ff(x)\n",
        "        return self.ln2(x + ff_out)\n",
        "\n",
        "def build_model(vocab_size=16000, max_len=256, d_model=384, layers=6, heads=6):\n",
        "    inputs = tf.keras.Input(shape=(max_len,), dtype=tf.int32)\n",
        "\n",
        "    embed = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "\n",
        "\n",
        "    pos = tf.range(max_len)[tf.newaxis, :]\n",
        "    pos_embed = tf.keras.layers.Embedding(max_len, d_model)(pos)\n",
        "    x = embed + pos_embed\n",
        "\n",
        "    mask = tf.linalg.band_part(tf.ones((max_len, max_len)), -1, 0)\n",
        "    mask = tf.cast(mask, tf.bool)  # Keras wants boolean mask\n",
        "\n",
        "\n",
        "    for _ in range(layers):\n",
        "        x = DecoderBlock(d_model, heads, d_ff=4 * d_model)(x, mask)\n",
        "\n",
        "    logits = tf.keras.layers.Dense(vocab_size)(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, logits)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "op1nkZcfqmil",
        "outputId": "21c0f931-17f9-491b-d98d-ca204fc4a233"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_block_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,774,464</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_block_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,774,464</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_block_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,774,464</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_block_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,774,464</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_block_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,774,464</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_block_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,774,464</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16000</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,160,000</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │     \u001b[38;5;34m6,144,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_block_1 (\u001b[38;5;33mDecoderBlock\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │     \u001b[38;5;34m1,774,464\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_block_2 (\u001b[38;5;33mDecoderBlock\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │     \u001b[38;5;34m1,774,464\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_block_3 (\u001b[38;5;33mDecoderBlock\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │     \u001b[38;5;34m1,774,464\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_block_4 (\u001b[38;5;33mDecoderBlock\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │     \u001b[38;5;34m1,774,464\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_block_5 (\u001b[38;5;33mDecoderBlock\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │     \u001b[38;5;34m1,774,464\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_block_6 (\u001b[38;5;33mDecoderBlock\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │     \u001b[38;5;34m1,774,464\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16000\u001b[0m)     │     \u001b[38;5;34m6,160,000\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,950,784</span> (87.55 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,950,784\u001b[0m (87.55 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,950,784</span> (87.55 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,950,784\u001b[0m (87.55 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdStrQkIqn5L",
        "outputId": "66334aa2-559a-4d14-b341-5de792ed78c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m6934/6934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m660s\u001b[0m 88ms/step - loss: 1.7427\n",
            "Epoch 2/3\n",
            "\u001b[1m6934/6934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m638s\u001b[0m 88ms/step - loss: 1.6632\n",
            "Epoch 3/3\n",
            "\u001b[1m6934/6934\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m639s\u001b[0m 88ms/step - loss: 1.6006\n"
          ]
        }
      ],
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True\n",
        ")\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-4)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_fn\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_ds,\n",
        "    epochs=3,\n",
        "    batch_size=32\n",
        ")\n",
        "model.save('model_9.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_xQugLPqsQE",
        "outputId": "46e897d4-8965-4a75-b89a-65fc8b85551b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<user>: Hey bro <assistant>: hermos偿 hermosua hermosuah terminal ob hermos。令 hermos年 hermos。令。eceh sir hermos。令 hermosuaheceh lyrics ob hermos。架 hermos。令 ob hermossl hermosas hermossl hermosamenteh llegó ob hermosamente hermosamente hermosamente hermossl令 faster\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "def generate(prompt, max_new=50):\n",
        "    ids = sp.encode(prompt, out_type=int)\n",
        "\n",
        "    for _ in range(max_new):\n",
        "        x = ids[-256:]\n",
        "        pad = [sp.pad_id()] * (256 - len(x))\n",
        "        x = pad + x\n",
        "        x = tf.constant([x])\n",
        "\n",
        "        seq_len = len(ids)\n",
        "        logits = model(x)[0, -1]\n",
        "        next_id = int(tf.argmax(logits))\n",
        "        ids.append(next_id)\n",
        "\n",
        "        if next_id == sp.eos_id():\n",
        "            break\n",
        "\n",
        "    return sp.decode(ids)\n",
        "\"\"\"\n",
        "\n",
        "def generate(prompt, sp, model, max_new_tokens=60, temperature=0.6, top_k=30):\n",
        "    # Encode initial tokens\n",
        "    ids = sp.encode(prompt)\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        # Keep only last 256 tokens if needed\n",
        "        x = ids[-256:]\n",
        "\n",
        "        # Pad to fixed length\n",
        "        pad_len = 256 - len(x)\n",
        "        x_padded = [sp.pad_id()] * pad_len + x\n",
        "\n",
        "        x_tensor = tf.constant([x_padded])\n",
        "\n",
        "        # Forward pass → get logits of last token\n",
        "        logits = model(x_tensor)[0, -1]\n",
        "\n",
        "        # -------------------------\n",
        "        #   Repetition blocking\n",
        "        # -------------------------\n",
        "        if len(ids) > 1:\n",
        "            last_id = ids[-1]\n",
        "            logits = tf.tensor_scatter_nd_update(\n",
        "                logits,\n",
        "                indices=[[last_id]],\n",
        "                updates=[-1e9]\n",
        "            )\n",
        "\n",
        "        # -------------------------\n",
        "        #      Temperature\n",
        "        # -------------------------\n",
        "        logits = logits / temperature\n",
        "\n",
        "        # -------------------------\n",
        "        #         Top-K\n",
        "        # -------------------------\n",
        "        values, indices = tf.nn.top_k(logits, k=top_k)\n",
        "        probs = tf.nn.softmax(values)[None, :]  # batch dims\n",
        "\n",
        "        # Sample from top-k logits\n",
        "        next_k = tf.random.categorical(tf.math.log(probs), 1)[0, 0].numpy()\n",
        "        next_token = int(indices[next_k])\n",
        "\n",
        "        ids.append(next_token)\n",
        "\n",
        "        # Stop on EOS\n",
        "        if next_token == sp.eos_id():\n",
        "            break\n",
        "\n",
        "    return sp.decode(ids)\n",
        "\n",
        "\n",
        "print(generate(\"<user>: Hey bro\\n<assistant>:\", sp, model))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
